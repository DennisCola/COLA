import streamlit as st
import pandas as pd
import google.generativeai as genai
from docx import Document
import json
import re
from io import BytesIO

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="å¥§æ·è¡Œç¨‹ AI è‡ªå‹•è½‰è¡¨", layout="wide")

if "GEMINI_API_KEY" not in st.secrets:
    st.error("è«‹åœ¨ Secrets è¨­å®š GEMINI_API_KEY"); st.stop()

# ä¿®æ­£æ¨¡å‹åˆå§‹åŒ–ï¼šç›´æ¥ä½¿ç”¨å­—ä¸²åç¨±ï¼Œä¸åŠ  models/ å‰ç¶´
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-flash')

# æ ¸å¿ƒ 6 æ¬„ä½
COLS = ["å¤©æ•¸", "è¡Œç¨‹å¤§é»", "åˆé¤", "æ™šé¤", "æœ‰æ–™é–€ç¥¨", "æ—…é¤¨"]

st.title("ğŸŒ å¥§æ·è¡Œç¨‹ AI è‡ªå‹•è½‰è¡¨ (å¼·åŠ›æå–ç‰ˆ)")
st.info("ğŸ’¡ é‹ä½œæ¨¡å¼ï¼šä¸Šå‚³ Word å¾Œï¼ŒAI æœƒè‡ªå‹•æå–ç´”æ–‡å­—ä¸¦æ­¸é¡ç‚º 6 å€‹æ ¸å¿ƒæ¬„ä½ã€‚")

# --- 2. æª”æ¡ˆä¸Šå‚³èˆ‡è™•ç† ---
up = st.file_uploader("1. ä¸Šå‚³è¡Œç¨‹ Word (.docx)", type=["docx"])

if up:
    # ç•¶æª”æ¡ˆæ›´æ›æ™‚ï¼Œè§¸ç™¼é‡æ–°è¾¨è­˜
    if 'fn' not in st.session_state or st.session_state.fn != up.name:
        try:
            # A. è®€å– Word ä¸¦è½‰æ›ç‚ºç´”æ–‡å­—
            doc = Document(up)
            text_list = []
            
            # è®€å–æ‰€æœ‰æ®µè½æ–‡å­—
            for p in doc.paragraphs:
                if p.text.strip():
                    text_list.append(p.text.strip())
            
            # è®€å–æ‰€æœ‰è¡¨æ ¼æ–‡å­— (æ—…è¡Œç¤¾è¡Œç¨‹é€šå¸¸åœ¨è¡¨æ ¼è£¡)
            for tbl in doc.tables:
                for row in tbl.rows:
                    cells = [c.text.strip() for c in row.cells if c.text.strip()]
                    if cells:
                        # ä½¿ç”¨ dict.fromkeys ç§»é™¤åˆä½µå„²å­˜æ ¼ç”¢ç”Ÿçš„é‡è¤‡æ–‡å­—
                        text_list.append(" | ".join(dict.fromkeys(cells)))
            
            pure_text = "\n".join(text_list)
            st.session_state.current_text = pure_text
            
            st.info("ğŸ”„ æ­£åœ¨é€é Gemini-1.5-Flash é€²è¡Œ 6 æ¬„ä½åˆ†é¡...")

            # B. é¤µçµ¦ AI é€²è¡Œç´”æ–‡å­—åˆ†é¡
            prompt = f"""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­ç·šæ§ã€‚è«‹æ ¹æ“šä»¥ä¸‹è¡Œç¨‹æ–‡å­—ï¼Œå°‡å…§å®¹ç²¾æº–åˆ†é¡ç‚º JSON åˆ—è¡¨æ ¼å¼ã€‚
            æ¬„ä½å¿…é ˆç‚ºï¼š{','.join(COLS)}ã€‚
            
            ã€æŒ‡ä»¤ã€‘ï¼š
            - ã€å¤©æ•¸ã€ï¼šæ¨™è¨» 1, 2, 3...ã€‚
            - ã€è¡Œç¨‹å¤§é»ã€ï¼šé€ è¨ªçš„ä¸»è¦åŸå¸‚æˆ–åœ°å€ã€‚
            - ã€åˆé¤/æ™šé¤ã€ï¼šå…·é«”é¤é£²å…§å®¹ã€‚
            - ã€æœ‰æ–™é–€ç¥¨ã€ï¼šæåŠã€å«é–€ç¥¨ã€ã€ã€å…¥å…§ã€çš„æ™¯é»ã€‚
            - ã€æ—…é¤¨ã€ï¼šé£¯åº—åç¨±èˆ‡æ˜Ÿç­‰ã€‚
            - æ‰¾ä¸åˆ°è³‡è¨Šè«‹å¡«ç©ºå­—ä¸² ""ã€‚
            - ä¸è¦åŒ…å« Markdown æ¨™ç±¤ï¼Œåªè¦ç´” JSON åˆ—è¡¨ã€‚
            
            å…§å®¹ï¼š
            {pure_text[:5000]}
            """
            
            res = model.generate_content(prompt)
            
            # C. è§£æå›å‚³å…§å®¹ (ä½¿ç”¨æ›´å¼·å¤§çš„æ­£å‰‡è¡¨é”å¼)
            js_match = re.search(r'\[.*\]', res.text, re.DOTALL)
            if js_match:
                data = json.loads(js_match.group(0))
                st.session_state.df = pd.DataFrame(data).reindex(columns=COLS).fillna("").astype(str)
                st.session_state.fn = up.name
                st.success("âœ… è‡ªå‹•åˆ†é¡å®Œæˆï¼")
            else:
                st.error("AI è¾¨è­˜çµæœç„¡æ³•è§£æç‚º JSONï¼Œè«‹é‡è©¦ã€‚")
                
        except Exception as e:
            st.error(f"æª”æ¡ˆè®€å–æˆ–è¾¨è­˜å¤±æ•—ï¼š{str(e)}")

# --- 3. é¡¯ç¤ºèˆ‡æ ¸å°è¡¨æ ¼ ---
if 'df' in st.session_state:
    st.divider()
    st.subheader("ğŸ“ AI åˆ†é¡æ ¸å°è¡¨")
    
    # è®“ç·šæ§å¯ä»¥ç›´æ¥ä¿®æ”¹
    edited_df = st.data_editor(
        st.session_state.df, 
        use_container_width=True, 
        num_rows="dynamic",
        key="itinerary_editor"
    )
    
    # åµéŒ¯å·¥å…·
    with st.expander("ğŸ” æª¢è¦– Word æå–å‡ºçš„ç´”æ–‡å­—"):
        if 'current_text' in st.session_state:
            st.text_area("ç´”æ–‡å­—å…§å®¹ï¼š", st.session_state.current_text, height=300)
