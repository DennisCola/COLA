import streamlit as st
import pandas as pd
import requests
from io import BytesIO
from docx import Document
import google.generativeai as genai
import json

# --- 1. åˆå§‹åŒ–èˆ‡é é¢è¨­å®š ---
st.set_page_config(page_title="AIç·šæ§è½‰è¡¨å·¥å…·", layout="wide")

if "GEMINI_API_KEY" not in st.secrets:
    st.error("è«‹åœ¨ Secrets ä¸­è¨­å®š GEMINI_API_KEY")
    st.stop()

genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-flash')

# 11 å€‹æ¨™æº–æ¬„ä½èˆ‡ Sheet é€£çµ
COLS = ["æ—¥æœŸ", "æ˜ŸæœŸ", "å¤©æ•¸", "è¡Œç¨‹å¤§é»", "åˆé¤", "é¤æ¨™", "æ™šé¤", "é¤æ¨™", "æœ‰æ–™é–€ç¥¨", "æ—…é¤¨", "æ˜Ÿç­‰"]
URL = "https://docs.google.com/spreadsheets/d/1y53LHsJkDx2xA1MsLzkdd5FYQYWcfQrhs2KeSbsKbZk/export?format=xlsx"

# --- 2. è³‡æ–™åº«é€£å‹•æª¢æŸ¥ ---
@st.cache_data(ttl=300)
def load_db():
    try:
        r = requests.get(URL)
        with BytesIO(r.content) as f:
            # è®€å–ä¸‰å€‹åˆ†é ä»¥ç¢ºèª Sheet é€£çµæ­£å¸¸
            f_db = pd.read_excel(f, "Fixed")
            s_db = pd.read_excel(f, "Shared")
            d_db = pd.read_excel(f, "Daily")
            return f_db, s_db, d_db
    except:
        return None, None, None

db_f, db_s, db_d = load_db()

st.title("ğŸ“„ è¡Œç¨‹è‡ªå‹•è½‰è¡¨ (ç´”æ·¨ç©©å®šç‰ˆ)")

if db_f is not None:
    st.success("âœ… æˆæœ¬è³‡æ–™åº«é€£å‹•æˆåŠŸ")
else:
    st.error("âŒ è³‡æ–™åº«é€£å‹•å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ– Sheet é€£çµ")

# --- 3. Word è™•ç†é‚è¼¯ (å¿½ç•¥åœ–ç‰‡ã€åªè®€æ–‡å­—) ---
up = st.file_uploader("1. ä¸Šå‚³è¡Œç¨‹ Word (.docx)", type=["docx"])

if up:
    # å¦‚æœæª”æ¡ˆåç¨±è®Šäº†ï¼Œæ¸…ç©ºèˆŠå¿«å–
    if 'fn' not in st.session_state or st.session_state.fn != up.name:
        st.session_state.fn = up.name
        if 'df' in st.session_state:
            del st.session_state.df

    if 'df' not in st.session_state:
        try:
            doc = Document(up)
            # åƒ…æŠ“å–æ®µè½èˆ‡è¡¨æ ¼å…§çš„æ–‡å­—ï¼Œé€™æœƒè‡ªå‹•éæ¿¾åœ–ç‰‡
            txt_list = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
            for tbl in doc.tables:
                for row in tbl.rows:
                    for cell in row.cells:
                        if cell.text.strip():
                            txt_list.append(cell.text.strip())
            
            st.info("ğŸ”„ AI æ­£åœ¨é–±è®€è¡Œç¨‹ï¼Œä¸¦ä¾ç…§æ ¼å¼ç•™ç™½...")
            
            # é¤µçµ¦ AI çš„å…§å®¹é™åˆ¶åœ¨ 3000 å­—å…§ï¼Œé˜²æ­¢è¶…å‡º Token é™åˆ¶
            prompt = f"""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­ç·šæ§åŠ©ç†ã€‚è«‹è®€è¡Œç¨‹ä¸¦è½‰æ›ç‚º JSON åˆ—è¡¨ã€‚
            æ¬„ä½å¿…é ˆåŒ…å«ï¼š{','.join(COLS)}ã€‚
            ã€è¦å‰‡ã€‘ï¼š
            1. æ‰¾ä¸åˆ°è³‡è¨Šã€è®€ä¸æ‡‚æˆ–ç„¡è³‡æ–™çš„æ ¼å­ï¼Œè«‹ã€Œç›´æ¥ç•™ç©ºå­—ä¸² ""ã€ã€‚
            2. ä¸è¦å¯«è§£é‡‹æ–‡å­—ã€‚
            3. å¤©æ•¸è«‹å¡«ç´”æ•¸å­—ã€‚
            å…§å®¹ï¼š{(' '.join(txt_list))[:3000]}
            """
            
            res = model.generate_content(prompt)
            # æ¸…æ´— Markdown æ¨™ç±¤ä¸¦è½‰ç‚º JSON
            js_txt = res.text.replace('```json', '').replace('```', '').strip()
            data = json.loads(
