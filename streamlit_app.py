import streamlit as st
import pandas as pd
import requests
from io import BytesIO
from docx import Document
import google.generativeai as genai
import json

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="AIç·šæ§è½‰è¡¨å·¥å…·", layout="wide")

if "GEMINI_API_KEY" not in st.secrets:
    st.error("è«‹åœ¨ Secrets ä¸­è¨­å®š GEMINI_API_KEY")
    st.stop()

genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-flash')

# 11 å€‹æ¨™æº–æ¬„ä½èˆ‡è³‡æ–™åº«é€£çµ
COLS = ["æ—¥æœŸ", "æ˜ŸæœŸ", "å¤©æ•¸", "è¡Œç¨‹å¤§é»", "åˆé¤", "é¤æ¨™", "æ™šé¤", "é¤æ¨™", "æœ‰æ–™é–€ç¥¨", "æ—…é¤¨", "æ˜Ÿç­‰"]
URL = "https://docs.google.com/spreadsheets/d/1y53LHsJkDx2xA1MsLzkdd5FYQYWcfQrhs2KeSbsKbZk/export?format=xlsx"

# --- 2. è³‡æ–™åº«é€£å‹•æª¢æŸ¥ ---
@st.cache_data(ttl=300)
def load_db():
    try:
        r = requests.get(URL)
        with BytesIO(r.content) as f:
            # è®€å–ä¸‰å€‹åˆ†é ä»¥ç¢ºèª Sheet é€£çµæ­£å¸¸
            return pd.read_excel(f, "Fixed"), pd.read_excel(f, "Shared"), pd.read_excel(f, "Daily")
    except:
        return None, None, None

db_f, db_s, db_d = load_db()

st.title("ğŸ“„ è¡Œç¨‹è‡ªå‹•è½‰è¡¨ (æ ¸å°å°ˆç”¨ç‰ˆ)")

if db_f is not None:
    st.success("âœ… æˆæœ¬è³‡æ–™åº«é€£å‹•æˆåŠŸ")
else:
    st.error("âŒ è³‡æ–™åº«é€£å‹•å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¬Šé™")

# --- 3. Word è™•ç†é‚è¼¯ ---
up = st.file_uploader("ä¸Šå‚³è¡Œç¨‹ Word (.docx)", type=["docx"])

if up:
    # æª”æ¡ˆæ›´æ›æª¢æŸ¥
    if 'fn' not in st.session_state or st.session_state.fn != up.name:
        st.session_state.fn = up.name
        if 'df' in st.session_state:
            del st.session_state.df

    if 'df' not in st.session_state:
        try:
            doc = Document(up)
            # åƒ…æå–æ®µè½æ–‡å­—èˆ‡è¡¨æ ¼æ–‡å­—ï¼ˆè‡ªå‹•éæ¿¾åœ–ç‰‡ï¼‰
            txts = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
            for tbl in doc.tables:
                for row in tbl.rows:
                    for cell in row.cells:
                        if cell.text.strip():
                            txts.append(cell.text.strip())
            
            st.info("ğŸ”„ AI æ­£åœ¨å»è•ªå­˜èï¼Œè«‹ç¨å€™...")
            
            # æŒ‡ä»¤ AI æ‰¾ä¸åˆ°å°±ç•™ç™½ ""
            pm = f"""ä½ æ˜¯ä¸€åæ—…éŠåŠ©ç†ã€‚è«‹è®€è¡Œç¨‹ä¸¦è½‰æ›ç‚º JSON åˆ—è¡¨ã€‚
            æ¬„ä½ï¼š{','.join(COLS)}ã€‚
            è¦å‰‡ï¼šæ‰¾ä¸åˆ°è³‡è¨Šã€è®€ä¸æ‡‚æˆ–ç„¡è³‡æ–™çš„æ ¼å­è«‹ç›´æ¥å¡«ç©ºå­—ä¸² ""ã€‚
            å…§å®¹ï¼š{(' '.join(txts))[:2500]}"""
            
            res = model.generate_content(pm)
            js_txt = res.text.replace('```json', '').replace('```', '').strip()
            data = json.loads(js_txt)
            
            # è½‰æ›ç‚º DataFrame ä¸¦å¼·åˆ¶å‹åˆ¥ç‚ºå­—ä¸²ä»¥ç¢ºä¿ç©©å®š
            df_final = pd.DataFrame(data).reindex(columns=COLS).fillna("").astype(str)
            st.session_state.df = df_final
            
        except Exception as e:
            st.warning("âš ï¸ è¾¨è­˜é‡åˆ°å›°é›£ï¼Œå·²å»ºç«‹ç©ºç™½è¡¨æ ¼ã€‚")
            st.session_state.df = pd.DataFrame([["" for _ in COLS]], columns=COLS)

    # --- 4. é¡¯ç¤º 11 æ¬„æ ¸å°è¡¨ ---
    if 'df' in st.session_state:
        st.subheader("ğŸ“ ç·šæ§æ ¸å°è¡¨")
        st.caption("æ‚¨å¯ä»¥é»æ“Šæ ¼å­ç›´æ¥ä¿®æ”¹å…§å®¹ã€‚AI è®€ä¸åˆ°çš„è³‡è¨Šå·²è‡ªå‹•ç•™ç™½ã€‚")
        
        # ä½¿ç”¨å‹•æ…‹ Key éš”é›¢ä¸åŒæª”æ¡ˆçš„ç·¨è¼¯ç‹€æ…‹
        st.data_editor(
            st.session_state.df,
            use_container_width=True,
            num_rows="dynamic",
            key=f"editor_{st.session_state.fn}"
        )
