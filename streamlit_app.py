import streamlit as st
import pandas as pd
import requests
from io import BytesIO
from docx import Document
import google.generativeai as genai
import json
import re

st.set_page_config(page_title="ç·šæ§å°ˆç”¨-ç²¾æº–æå–ç‰ˆ", layout="wide")

if "GEMINI_API_KEY" not in st.secrets:
    st.error("è«‹è¨­å®š API Key"); st.stop()

genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-flash')

COLS = ["å¤©æ•¸", "è¡Œç¨‹å¤§é»", "åˆé¤", "æ™šé¤", "æœ‰æ–™é–€ç¥¨", "æ—…é¤¨"]

st.title("ğŸ›¡ï¸ çµæ§‹åŒ–è¡Œç¨‹æå– (ç©©å®šç‰ˆ)")
st.caption("æ”¹ç”¨è¡¨æ ¼æƒæèˆ‡ç¯„ä¾‹å¼•å°ï¼Œå¤§å¹…æå‡æå–ç²¾æº–åº¦ã€‚")

up = st.file_uploader("1. ä¸Šå‚³ .docx æª”æ¡ˆ", type=["docx"])

if up:
    if 'df' not in st.session_state or st.session_state.get('fn') != up.name:
        try:
            doc = Document(up)
            extracted_data = []
            
            # ç¬¬ä¸€éšæ®µï¼šå„ªå…ˆæƒæ Word å…§çš„è¡¨æ ¼å…§å®¹ï¼ˆæœ€ç²¾æº–ï¼‰
            for tbl in doc.tables:
                for row in tbl.rows:
                    row_txt = [c.text.strip() for c in row.cells if c.text.strip()]
                    if row_txt:
                        extracted_data.append(" | ".join(dict.fromkeys(row_txt)))
            
            # ç¬¬äºŒéšæ®µï¼šè£œè¶³æ®µè½å…§å®¹
            for p in doc.paragraphs:
                if p.text.strip(): extracted_data.append(p.text.strip())
            
            raw_text = "\n".join(extracted_data)
            st.session_state.raw_debug = raw_text 

            # å¼·åŠ›å¼•å° Prompt
            prompt = f"""
            ä½ æ˜¯ä¸€ä½å°ˆæ¥­ç·šæ§ã€‚è«‹å°‡è¡Œç¨‹æ–‡å­—è½‰æ›ç‚º JSONã€‚
            ç¯„ä¾‹è¼¸å…¥ï¼šã€Day 3 è–©çˆ¾æ–¯å ¡ã€‚åˆé¤ï¼šé±’é­šé¤ã€æ™šé¤ï¼šå…­èœä¸€æ¹¯ã€‚å…¥å…§ç¾æ³‰å®®ã€‚ä½ï¼šHILTONã€
            ç¯„ä¾‹è¼¸å‡ºï¼š[{{"å¤©æ•¸":"3","è¡Œç¨‹å¤§é»":"è–©çˆ¾æ–¯å ¡","åˆé¤":"é±’é­šé¤","æ™šé¤":"å…­èœä¸€æ¹¯","æœ‰æ–™é–€ç¥¨":"ç¾æ³‰å®®","æ—…é¤¨":"HILTON"}}]
            
            ç›®æ¨™æ ¼å¼ï¼š{json.dumps(COLS, ensure_ascii=False)}
            
            è¡Œç¨‹å…§å®¹ï¼š
            {raw_text[:4500]}
            """
            
            res = model.generate_content(prompt)
            # æ¿¾é™¤ AI å»¢è©±ï¼ŒåªæŠ“ JSON æ‹¬è™Ÿå…§å®¹
            match = re.search(r'\[.*\]', res.text, re.DOTALL)
            if match:
                data = json.loads(match.group(0))
                st.session_state.df = pd.DataFrame(data).reindex(columns=COLS).fillna("").astype(str)
                st.session_state.fn = up.name
            else:
                st.error("AI ç„¡æ³•è§£æçµæ§‹ï¼Œè«‹ç¢ºèª Word æ˜¯å¦æœ‰æ–‡å­—å…§å®¹ã€‚")

        except Exception as e:
            st.error(f"æå–å¤±æ•—: {e}")

    if 'df' in st.session_state:
        st.subheader("ğŸ“ æå–çµæœæ ¸å°")
        st.data_editor(st.session_state.df, use_container_width=True, num_rows="dynamic", key=f"ed_{up.name}")

    with st.expander("ğŸ” æŸ¥çœ‹åº•å±¤æå–æ–‡å­— (å¦‚æœæ²’æŠ“åˆ°ï¼Œè«‹ç¢ºèªæ­¤è™•æ˜¯å¦æœ‰å­—)"):
        if 'raw_debug' in st.session_state:
            st.text_area("æå–æ–‡æœ¬ï¼š", st.session_state.raw_debug, height=300)
