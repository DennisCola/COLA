import streamlit as st
import pandas as pd
import requests
from io import BytesIO
from docx import Document
import google.generativeai as genai
import json

st.set_page_config(page_title="AIå°ç·šæ§", layout="wide")

# 1. æ ¸å¿ƒè¨­å®š
if "GEMINI_API_KEY" not in st.secrets:
    st.error("è«‹å…ˆåœ¨ Secrets è¨­å®š GEMINI_API_KEY")
    st.stop()

genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
model = genai.GenerativeModel('gemini-1.5-flash')
URL = "https://docs.google.com/spreadsheets/d/1y53LHsJkDx2xA1MsLzkdd5FYQYWcfQrhs2KeSbsKbZk/export?format=xlsx"

# æ¨™æº– 11 æ¬„ä½
COLS = ["æ—¥æœŸ", "æ˜ŸæœŸ", "å¤©æ•¸", "è¡Œç¨‹å¤§é»", "åˆé¤", "é¤æ¨™", "æ™šé¤", "é¤æ¨™", "æœ‰æ–™é–€ç¥¨", "æ—…é¤¨", "æ˜Ÿç­‰"]

# 2. å´é‚Šæ¬„
with st.sidebar:
    st.header("âš¡ å ±åƒ¹åƒæ•¸")
    ex = st.number_input("æ­å…ƒåŒ¯ç‡", value=35.0)
    ab = st.number_input("æ©Ÿç¥¨ç¥¨åƒ¹", value=32000)
    at = st.number_input("æ©Ÿç¥¨ç¨…é‡‘", value=7500)
    pt = st.number_input("ç›®æ¨™åˆ©æ½¤", value=8000)

@st.cache_data(ttl=300)
def load():
    try:
        r = requests.get(URL)
        with BytesIO(r.content) as f:
            return pd.read_excel(f, "Fixed"), pd.read_excel(f, "Shared"), pd.read_excel(f, "Daily")
    except: return None, None, None

db_f, db_s, db_d = load()
st.title("ğŸŒ AIå°ç·šæ§(ç®—å ±åƒ¹)")

if db_f is not None:
    st.success("âœ… è³‡æ–™åº«å·²é€£ç·š")
    up = st.file_uploader("1. ä¸Šå‚³è¡Œç¨‹ Word (.docx)", type=["docx"])
    
    if up:
        # é‡ç½® State ä»¥ç¢ºä¿æ–°æª”æ¡ˆèƒ½é‡æ–°è®€å–
        if 'last_file' not in st.session_state or st.session_state.last_file != up.name:
            st.session_state.last_file = up.name
            if 'df_e' in st.session_state: del st.session_state.df_e

        if 'df_e' not in st.session_state:
            try:
                doc = Document(up)
                # ã€é—œéµä¿®æ­£ã€‘åªæŠ“å–æ–‡å­—æ®µè½ï¼Œå¾¹åº•å¿½ç•¥åœ–ç‰‡èˆ‡äº‚ç¢¼ç‰©ä»¶
                paras = []
                for p in doc.paragraphs:
                    clean_text = p.text.strip()
                    if clean_text: # åªæœ‰éç©ºç™½çš„æ–‡å­—æ®µè½æ‰åŠ å…¥
                        paras.append(clean_text)
                
                # åŒæ™‚æŠ“å–è¡¨æ ¼ä¸­çš„æ–‡å­—ï¼ˆè¨±å¤šè¡Œç¨‹æ˜¯åœ¨è¡¨æ ¼è£¡ï¼‰
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            cell_text = cell.text.strip()
                            if cell_text:
                                paras.append(cell_text)
                
                tx = "\n".join(paras)
                
                st.info("ğŸ”„ AI æ­£åœ¨éæ¿¾åœ–ç‰‡ä¸¦é€²è¡Œå»è•ªå­˜è...")
                
                prom = f"ä½ æ˜¯åŠ©ç†ã€‚è®€å–è¡Œç¨‹ä¸¦å›å‚³JSONæ ¼å¼åˆ—è¡¨ï¼ŒåŒ…å«ï¼š{','.join(COLS)}ã€‚ç„¡å…§å®¹å¡«Xã€‚å…§å®¹ï¼š{tx[:3000]}"
                res = model.generate_content(prom)
                raw = res.text.replace('```json', '').replace('```', '').strip()
                js_data = json.loads(raw)
                
                temp_df = pd.DataFrame(js_data)
                temp_df = temp_df.reindex(columns=COLS).fillna("X").astype(str)
                st.session_state.df_e = temp_df
            except Exception as e:
                st.warning("âš ï¸ è¾¨è­˜é‡åˆ°å›°é›£ï¼Œå·²å»ºç«‹ç©ºç™½æ¨¡æ¿ã€‚")
                st.session_state.df_e = pd.DataFrame([["D1","X","1","è«‹æ‰‹å‹•è¼¸å…¥","X","X","X","X","X","X","X"]], columns=COLS)

        st.header("2. ç·šæ§æ ¸å°è¡¨")
        final = st.data_editor(st.session_state.df_e, use_container_width=True, num_rows="dynamic")

        if st.button("ç¢ºèªç„¡èª¤ï¼Œè¨ˆç®—å ±åƒ¹"):
            st.divider()
            tot_e = 0
            # æ¯”å°é‚è¼¯ï¼šå°‡ç•¶å¤©æ‰€æœ‰è³‡è¨Šåˆä½µå¾Œæœå°‹è³‡æ–™åº«é—œéµå­—
            for _, r in final.iterrows():
                row_t = f"{r['åˆé¤']} {r['æ™šé¤']} {r['æœ‰æ–™é–€ç¥¨']}"
                for _, dr in db_f.iterrows():
                    if str(dr['åˆ¤æ–·æ–‡å­—']) in row_t: 
                        tot_e += float(
